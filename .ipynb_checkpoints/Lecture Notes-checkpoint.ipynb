{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lecture 2: Linear Regression #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y =ax: correct part: it models the increasing trend of the dataset correctly (the slope of the graph)\n",
    "- 1/2 for RMSE: just a parameter that helps with the maths, but doesnâ€™t affect the final results of the learning / parameters\n",
    "- learning rate \\alpha: predefined\n",
    "- epoch: a particular period of time\n",
    "- one problem of gradient descent: it guarantees to find a minimum, but may not be the global minimum (can be local minimum)\n",
    "- interpretation: meaningfulness, impact-fulness, slope (value of a), parameters, informative\n",
    "- stratified sampling: subdividing the dataset into sub-groups and select data points from each sub-group randomly\n",
    "- practical: California housing dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Classification\n",
    "- Normal three classifiers: SVM, NB, SVM with kernel trick\n",
    "- Other classifiers and problems:\n",
    "    - Bagging and the Bias/Variance Trade-off\n",
    "    - Model's generalisation error:\n",
    "        - Bias: due to wrong assumption -> use __*bagging*__ to reduce\n",
    "        - Variance: due to model's excessive sensibility to small variations -> use __*boosting*__ to reduce\n",
    "        - Irreducible error: due to noise in the data -> use __*stacking*__ to improve prediction results\n",
    "    - Trade-off:\n",
    "        - increasing model's complexity increases its variance and reduce bias\n",
    "    - Random Forest Classifier\n",
    "    - AdaBoost: initialise with an initial weight vector\n",
    "    - Gradient Boosting: each round, get the error between this prediction __p__ and the previous round of prediction __p'__\n",
    "    - Stacking: an approach to ensemble the learnings (different decisions made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lecture 4: Classification 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5: Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6: PCA\n",
    "- Reduce the components to lower-dimensionality space with orthorgnal vectors (not necessarily orthorgonal. However we use orthorgonal vectores because of their convenience.\n",
    "- PCA: an algorithm that learns a coordinate system (with lower dimensionality) to represent the training data\n",
    "    - E.g. encode each data-point (a 2D point) into a 1D distance value\n",
    "- Autoencoder: (self-supervised)\n",
    "    - training phase: train both encoder and decoder \n",
    "    - decoder: produce a normal distribution for the class of the outputs\n",
    "    - self-supervised: treate all data as response (how we treate random variables differently)\n",
    "    - decoder will not decode the latent dimensionality into the original structure of data, but decode into a __*distribution*__ of the original data points with differnet ways of representation (see the graphical representation of tSNE and PCA)\n",
    "- tSNE (t-Distributed Stochastic Neighbor Embedding (t-SNE):\n",
    "    - however the structure and dimensionality of the dataset change, the relative ranking of the neighbour points will not be changes (it doesn't really care about the absolute distance)\n",
    "    - it only wants to reserve the ratio of the distances between its neighbour points and keeps the ratio to be the same\n",
    "    - e.g. change the country names which were 2D to a 1D latent embeddding using the ratio of the distance between the alphabets of the initials (very dumb and meaningless)\n",
    "- Don't always use alphabetical ordering. Use the content of the dataset to find a meaningful scale to represent the graph.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
